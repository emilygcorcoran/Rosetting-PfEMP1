####the below code was conducted in Jupyter Notebooks, using Python
##import Python Libraries
#essentials
import pandas as pd
#for plots
import matplotlib.pyplot as plt
import seaborn as sns
#essentials
import os
#essentials
from Bio import SeqIO
#pairwise distances
import Levenshtein as lv
#other
import nbformat

#list all files containing the VAR2CSA sequences (they should be fasta files)
fasta_files = [f for f in os.listdir() if f.endswith('.fasta')] #Â list comprehension
fasta_files

#create table with the sequences and their IDs
all_data = []
for fasta_file in fasta_files:
    records = list(SeqIO.parse(fasta_file, "fasta"))
    data = {'filename': os.path.basename(fasta_file),
            'sequence_id': [record.id for record in records],
           'sequence': [str(record.seq) for record in records]}
    all_data.append(pd.DataFrame(data))
start_df = pd.concat(all_data, ignore_index=True) #put the table in the correct format
start_df = start_df.sort_values(by='sequence_id') #sort values by sequence ID
start_df

#create a table for the metadata, replace that which is within " " with the file name, should be a csv file
metadata_df = pd.read_csv("vardb_var2csa.cleaned.isolates.population.csv").sort_values(by='sequence_id') 
metadata_df

#then merge both tables together
#column names + gene names within column should exactly match in both dataframes
df = start_df.merge(metadata_df, on = 'sequence_id',how='inner') 
#save the table
#df.to_csv("df_with_geo.csv")
df

missing_ids = df['sequence_id'].isnull().sum()
if missing_ids > 0:
    print(f"There are {missing_ids} missing sequence IDs.")
# Check for duplicates
duplicate_ids = df['sequence_id'].duplicated().sum()
if duplicate_ids > 0:
    print(f"There are {duplicate_ids} duplicated sequence IDs.")

df = df.drop_duplicates(subset='sequence_id', keep='first')
df

#extract sequence info from the table
sequence_dict = dict(zip(df['sequence_id'], df['sequence'])) #create a dictionary which assigns each sequence to its sequence ID
sequence_ids = list(sequence_dict.keys()) #take out sequence IDs
sequences = list(sequence_dict.values()) #take out sequences
#create Levenshtein distance matrix
n = len(sequences)
lev_matrix = [[lv.distance(sequences[i], sequences[j]) for j in range(n)] for i in range(n)]
lev_matrix=pd.DataFrame(lev_matrix)
lev_matrix

# Plot a clustermap of the Levenshtein distance matrix
plt.figure(figsize=(8, 6))
sns.clustermap(lev_matrix, cmap='viridis', vmin=0, vmax=4000)
plt.title("Levenshtein Distance Heatmap")
plt.savefig("heatmap_clustered.png")
plt.show()

###The below code it used to calculate the percentage of non duplicate amino acid sequences 
    #the number of columns of the "identical_seq_df" give the total number of sequences (n)
    #the number of columns of the "identical_seq_counts" gives the number of sequences after all duplicates are removed(m)
    #a simple calculation can be used to calculate the "non-duplicate" percentage: (m / n) * 100

identical_seq_counts = df['sequence'].value_counts().reset_index()
identical_seq_counts.columns = ['sequence', 'count']
identical_seq_counts
# Merge the two DataFrames on the 'sequence' column
identical_seq_df = pd.merge(identical_seq_counts, df, on='sequence', suffixes=('_df1', '_df2'))
identical_seq_df
