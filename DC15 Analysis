####The below code was conduted using Python in Jupyter Notebooks
##Import Python Libraries

#essentials
import pandas as pd
#for plots
import matplotlib.pyplot as plt
import seaborn as sns
#essentials
import os
#essentials
from Bio import SeqIO
#pairwise distances
import Levenshtein as lv
#for plots
import plotly.express as px
#clustering
from sklearn.manifold import MDS
#clustering
import numpy as np
#other
import nbformat


####Full-Length (no ATS) PfEMP1 Amino Acid Sequence Analysis

#list all files with the DC15-containing PfEMP1 sequences (they should be fasta files), sequences are that of full-length proteins apart from the Acidic Terminal Segment
fasta_files = [f for f in os.listdir() if f.endswith('ATS.fasta')] # list comprehension
fasta_files

#create table with the sequences and their IDs
all_data = []
for fasta_file in fasta_files:
    records = list(SeqIO.parse(fasta_file, "fasta"))
    data = {'filename': os.path.basename(fasta_file),
            'sequence_id': [record.id for record in records],
           'sequence': [str(record.seq) for record in records]}
    all_data.append(pd.DataFrame(data))
start_df = pd.concat(all_data, ignore_index=True) #put the table in the correct format
start_df = start_df.sort_values(by='sequence_id') #sort values by sequence ID
start_df

#create a table for the metadata, replace that which is within the double quotations with your file name (keep the double quotations in the code)
metadata_df = pd.read_csv("normalised.fulldataset.DC15_metadata_genes.csv").sort_values(by='Sample_ID') 
metadata_df = metadata_df.rename(columns={'Sample_ID': 'sequence_id'}) #should match the column from start_df
metadata_df

#then merge both tables together
#column names + gene names within column should exactly match in both dataframes
df = start_df.merge(metadata_df, on = 'sequence_id',how='inner') 
#save the table
df.to_csv("dc15meta_and_sequence.csv")
df

#create a table for the DC architecture, replace that which is within the double quotations with your file name (keep the double quotations in the code)
arcdc_df = pd.read_csv("normalised.fulldataset.all_DC15_matched_pattern.csv").sort_values(by='sequence_id') 
#arcdc_df = arcdc_df.rename(columns={'sequence_id'}) #should match the column from start_df
arcdc_df

#then merge tables together
#column names + gene names within column should exactly match in both dataframes
dc = df.merge(arcdc_df, on = 'sequence_id',how='inner') 
#save the table
#dc.to_csv("dc_with_geo.csv")
dc

dc.to_csv("dc15filterdf.csv")

#extract sequence info from the table
sequence_dict = dict(zip(dc['sequence_id'], dc['sequence'])) #create a dictionary which assigns each sequence to its sequence ID
sequence_ids = list(sequence_dict.keys()) #take out sequence IDs
sequences = list(sequence_dict.values()) #take out sequences
#create Levenshtein distance matrix
n = len(sequences)
lev_matrix = [[lv.distance(sequences[i], sequences[j]) for j in range(n)] for i in range(n)]
lev_matrix=pd.DataFrame(lev_matrix)
lev_matrix

#Plot a clustermap of the Levenshtein distance matrix
plt.figure(figsize=(8, 6))
#Set the vmin and vmax to control the color scale range
sns.clustermap(lev_matrix, cmap='viridis', vmin=0, vmax=4000)
#Set the title
plt.title("Levenshtein Distance Heatmap")
#Save the figure
plt.savefig("heatmap_clustered.png")
#Show the plot
plt.show()

##The below code it used to calculate the percentage of non duplicate amino acid sequences 
    #the number of columns of the "identical_seq_df" give the total number of sequences (n)
    #the number of columns of the "identical_seq_counts" gives the number of sequences after all duplicates are removed(m)
    #a simple calculation can be used to calculate the "non-duplicate" percentage: (m / n) * 100

identical_seq_counts = dc['sequence'].value_counts().reset_index()
identical_seq_counts.columns = ['sequence', 'count']
identical_seq_counts
# Merge the two DataFrames on the 'sequence' column
identical_seq_df = pd.merge(identical_seq_counts, dc, on='sequence', suffixes=('_df1', '_df2'))
identical_seq_df


####Domain-Specific Analysis

#list all files with the singular DC15-associated domain sequences (they should be fasta files)
domain_fasta = [f for f in os.listdir() if f.endswith('subclasses.fasta')] # list comprehension
domain_fasta

#create table with the sequences and their IDs
all_data_domain = []
for dseq in domain_fasta:
    records = list(SeqIO.parse(dseq, "fasta"))
    dataseq = {'filename': os.path.basename(dseq),
            'sequence_id': [record.id for record in records],
           'sequence': [str(record.seq) for record in records]}
    all_data_domain.append(pd.DataFrame(dataseq))
domain_df = pd.concat(all_data_domain, ignore_index=True) #put the table in the correct format
domain_df = domain_df.sort_values(by='sequence_id') #sort values by sequence ID
domain_df

###The below analysis was conducted for DBLa1.2, CIDRa1.5 and DBLb6
  #Sequences were extracted as such:
    filter1_2sub = domain_df[domain_df['sequence_id'].str.contains('DBLa1.2', na=False)]
    filter1_5sub = domain_df[domain_df['sequence_id'].str.contains('CIDRa1.5', na=False)]
    filterb6sub = domain_df[domain_df['sequence_id'].str.contains('DBLb6', na=False)]
  #Where names below are indicated as containing "1_2", names were replaced, as suitably relevant when conducting for domains CIDRa1.5 and DBLb6
  #Where names are indicated as "filter1_2sub", names were replaced with "filter1_5sub" or "filterb6sub" as relevant

##DBLa1.2 Example

#extract sequence info from the table
sequence_dict = dict(zip(filter1_2sub['sequence_id'], filter1_2sub['sequence'])) #create a dictionary which assigns each sequence to its sequence ID
sequence_ids = list(sequence_dict.keys()) #take out sequence IDs
sequences = list(sequence_dict.values()) #take out sequences
#create Levenshtein distance matrix
n = len(sequences)
lev_1_2matrix = [[lv.distance(sequences[i], sequences[j]) for j in range(n)] for i in range(n)]
lev_1_2matrix=pd.DataFrame(lev_1_2matrix)
lev_1_2matrix

#Plot a clustermap of the Levenshtein distance matrix
plt.figure(figsize=(8, 6))
#Set the vmin and vmax to control the color scale range
sns.clustermap(lev_1_2matrix, cmap='viridis', vmin=0, vmax=400)
#Set the title
plt.title("Levenshtein Distance Heatmap")
#Save the figure
plt.savefig("heatmap_1_2clustered.png")
#Show the plot
plt.show()

#calculate coordinates for 3D MDS plot 
#this might take a while depending on how many sequences you have
#create a new table for the MDS coordinates 
mds_1_2df = pd.DataFrame(filter1_2sub['sequence_id']).sort_index() #we'll keep the sequence IDs from the df table
#3D coordinates
mds_3d = MDS(n_components=3, random_state=42, dissimilarity='precomputed', n_init = 200, max_iter=500, n_jobs=5) 
mds_results_3d = mds_3d.fit_transform(lev_1_2matrix)
mds_1_2df['mds_3d']=mds_results_3d.tolist()
mds_1_2df['mds_3d_x']=mds_1_2df['mds_3d'].apply(lambda a: a[0]) #take out the 1st coordinate
mds_1_2df['mds_3d_y']=mds_1_2df['mds_3d'].apply(lambda b: b[1]) #take out the 2nd coordinate
mds_1_2df['mds_3d_z']=mds_1_2df['mds_3d'].apply(lambda c: c[2]) #take out the 3rd coordinate
mds_1_2df

#merge the MDS coordinates with our df
merged_1_2df = filter1_2sub.merge(mds_1_2df, on="sequence_id", how='right')
merged_1_2df
#save merged df
merged_1_2df.to_csv("merged_1_2df.csv")

#create 3D MDS plot
merged_1_2df = pd.read_csv("merged_1_2df.csv")
# Create the 3D MDS plot using the color map
fig = px.scatter_3d(merged_1_2df, x="mds_3d_x", y="mds_3d_y", z="mds_3d_z",  
                    hover_data=['sequence_id'])
# Choose camera angles (this is the view that will be used to save the image later)
camera = dict(
    eye=dict(x=1.25, y=1.25, z=0.5)
)
# Change the appearance of the plot
fig.update_layout(
    width=1000,
    height=700,
    template='plotly_white',
    scene=dict(
        aspectmode='cube'),
    scene_camera=camera
)
# Change the data point size and colour
fig.update_traces(marker=dict(color='red', size=6))
# Show the plot
fig.show()

##The below code it used to calculate the percentage of non duplicate amino acid sequences and proportion made up by the most common sequence
    #The below code was also repeated for CIDRa1.5 and DLBb6 with dataframe names changed as suitable
    #the number of columns of the "merged_1_2df" give the total number of sequences (n)
    #the number of columns of the "identical_seq_1_2df" gives the number of sequences after all duplicates are removed(m)
    #a simple calculation can be used to calculate the "non-duplicate" percentage: (m / n) * 100
    #the most common sequence will be listed first, its "count" value divided by the "n" value (number of columns of "merged_1_2df") and multiplied by 100 gives the proportion made up by the most common sequence

identical_seq_1_2df = merged_1_2df['sequence'].value_counts().reset_index()
# Rename the columns for clarity
identical_seq_1_2df.columns = ['sequence', 'count']
# Display the result
print(identical_seq_1_2df)

